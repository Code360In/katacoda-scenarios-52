{
    "authenticated": false,
    "backend":
    {
        "backendTarget": "client",
        "dockerimage": "python:3.8",
        "imageid": "python:3.8"
    },
    "description": "Learn how to quantize your model without losing precision",
    "details": {
        "finish": {
            "text": "finish.md"
        },
        "intro": {
            "code": "setup.sh",
            "text": "intro.md"
        },
        "steps": [
            {
                "text": "step1.md",
                "title": "Quantize Weights Using TensorFlow Lite's Converter"
            },
            {
                "text": "step2.md",
                "title": "Quantize Weights and Activations Using TensorFlow Lite's Converter"
            },
            {
                "text": "step3.md",
                "title": "Test the TensorFlow Lite Model Using the Python Interpreter"
            }
        ]
    },
    "difficulty": "Beginner",
    "environment": {
        "uidependencies":
        [
            "/socket.io/socket.io.js",
            "/javascripts/term.js",
            "/javascripts/terminal-application.js"
        ],
        "uilayout": "terminal-v1"
    },
    "id": "convert-pneumonia-model-with-tensorflow-lite",
    "katacoda":
    {
        "featureFlags":
        {
            "scripts": "v2"
        }
    },
    "pathwayId": "tensorflow-pneumonia",
    "pathwayTitle": "Tensorflow Pneumonia",
    "title": "Convert a TensorFlow Pneumonia Classifier to TensorFlow Lite with Quantization"
}